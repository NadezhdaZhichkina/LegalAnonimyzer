import re
import fitz
from docx import Document
from docx.shared import Pt
from docx.oxml.ns import qn
import streamlit as st
from io import BytesIO, StringIO

# === –ú–∞—Å–∫–∏—Ä–æ–≤–∫–∞ ===
def remove_sensitive_data(text):
    patterns = [
        # –§–ò–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á
        r'\b[–ê-–Ø–Å][–∞-—è—ë]+ [–ê-–Ø–Å][–∞-—è—ë]+ [–ê-–Ø–Å][–∞-—è—ë]+\b',
        # –ò–≤–∞–Ω–æ–≤ –ò.–ò.
        r'\b[–ê-–Ø–Å][–∞-—è—ë]+ [–ê-–Ø–Å]\.[–ê-–Ø–Å]\.\b',
        # –ò.–û. –ò–≤–∞–Ω–æ–≤
        r'\b[–ê-–Ø–Å]\.[–ê-–Ø–Å]\. ?[–ê-–Ø–Å][–∞-—è—ë]+\b',
        # –ò–ù–ù, –û–ì–†–ù, –ö–ü–ü
        r'\b–ò–ù–ù ?\d{10,12}\b',
        r'\b–û–ì–†–ù ?\d{13}\b',
        r'\b–ö–ü–ü ?\d{9}\b',
        # Email
        r'\b[\w\.-]+@[\w\.-]+\.\w+\b',
        # –¢–µ–ª–µ—Ñ–æ–Ω—ã
        r'(?:(?:8|\+7)[\s\-]?)?\(?\d{3,4}\)?[\s\-]?\d{2,3}[\s\-]?\d{2}[\s\-]?\d{2,4}',
        # URL –∏ –¥–æ–º–µ–Ω—ã
        r'https?://[^\s,]+',
        r'\b[\w\.-]+\.(ru|com|pdf|org|net)\b',
        # –ê–¥—Ä–µ—Å–∞
        r'(?i)(—é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π|–ø–æ—á—Ç–æ–≤—ã–π)?\s*–∞–¥—Ä–µ—Å\s*[:\-\u2013\u2014]?\s*[^\n\r]*',
        r'(?i)–º–µ—Å—Ç–æ–Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ\s*[:\-\u2013\u2014]?\s*[^\n\r]*',
        r'–≥\.\s?[–ê-–Ø–Å–∞-—è—ë]+,\s?—É–ª\.\s?[–ê-–Ø–Å–∞-—è—ë\s]+,\s?–¥\.\d+[\w]?,?\s?(—Å—Ç—Ä\.|–∫–æ—Ä–ø\.|–æ—Ñ\.)?\d*',
        # –ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã
        r'(?i)(—Ä–∞—Å—á–µ—Ç–Ω—ã–π —Å—á–µ—Ç|—Ä/—Å|–∫/—Å|–∫–æ—Ä/—Å|–∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç—Å–∫–∏–π —Å—á–µ—Ç)[^\n\r]*',
        # –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π
        # 1. –°–æ–∫—Ä–∞—â—ë–Ω–Ω—ã–µ –ø—Ä–∞–≤–æ–≤—ã–µ —Ñ–æ—Ä–º—ã —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –∫–∞–≤—ã—á–∫–∞–º–∏
        r'(?i)\b(–û–û–û|–ê–û|–ü–ê–û|–û–ê–û|–ó–ê–û|–ò–ü|–¢–°–ñ|–ú–£–ü|–ì–£–ü|–ù–ö–û|–ú–ö–ê|–°–ù–¢|–ü–ö|–ö–§–•|–ì–ú–ö)\s+[¬´"‚Äû‚Äú][^¬ª‚Äù"]+[¬ª‚Äù"](?:\s*[¬´"‚Äû‚Äú][^¬ª‚Äù"]+[¬ª‚Äù"])*',
        # 2. –ü–æ–ª–Ω—ã–µ –ø—Ä–∞–≤–æ–≤—ã–µ —Ñ–æ—Ä–º—ã —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –∫–∞–≤—ã—á–∫–∞–º–∏
        r'(?i)(–û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é|–ø—É–±–ª–∏—á–Ω–æ–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ|–Ω–µ–ø—É–±–ª–∏—á–Ω–æ–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ|–∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ|–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å|–ú—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω–æ–µ —É–Ω–∏—Ç–∞—Ä–Ω–æ–µ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ|–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ —É–Ω–∏—Ç–∞—Ä–Ω–æ–µ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ|–ù–µ–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è|–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –∫–æ–ª–ª–µ–≥–∏—è –∞–¥–≤–æ–∫–∞—Ç–æ–≤|–ê–¥–≤–æ–∫–∞—Ç—Å–∫–∞—è –∫–æ–Ω—Ç–æ—Ä–∞)\s+[¬´"‚Äû‚Äú][^¬ª‚Äù"]+[¬ª‚Äù"](?:\s*[¬´"‚Äû‚Äú][^¬ª‚Äù"]+[¬ª‚Äù"])*',
        # 3. –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –±–µ–∑ –∫–∞–≤—ã—á–µ–∫, –Ω–æ —Å –ø—Ä–∞–≤–æ–≤–æ–π —Ñ–æ—Ä–º–æ–π –≤ –∫–æ–Ω—Ü–µ
        r'(?i)[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)+\s+(–∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ|–ø—É–±–ª–∏—á–Ω–æ–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ|–Ω–µ–ø—É–±–ª–∏—á–Ω–æ–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ|–æ–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é)',
    ]

    replacements = {}
    for i, pattern in enumerate(patterns):
        def repl(match):
            key = f"[–£–î–ê–õ–ï–ù–û_{i}_{len(replacements)}]"
            replacements[key] = match.group()
            return key
        text = re.sub(pattern, repl, text)
    return text, replacements

# === –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ ===
def restore_sensitive_data(text, replacements):
    for key, original in replacements.items():
        text = text.replace(key, original)
    return text

# === –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —à—Ä–∏—Ñ—Ç–∞ ===
def set_font(paragraph):
    for run in paragraph.runs:
        run.font.name = 'Arial'
        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'Arial')
        run.font.size = Pt(11)

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ DOCX ===
def sanitize_docx(file_bytes):
    file_bytes.seek(0)
    doc = Document(BytesIO(file_bytes.read()))
    full_replacements = {}
    for para in doc.paragraphs:
        new_text, replacements = remove_sensitive_data(para.text)
        para.text = new_text
        set_font(para)
        full_replacements.update(replacements)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                new_text, replacements = remove_sensitive_data(cell.text)
                cell.text = new_text
                for p in cell.paragraphs:
                    set_font(p)
                full_replacements.update(replacements)
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer, full_replacements

def restore_docx(file_bytes, replacements):
    file_bytes.seek(0)
    doc = Document(BytesIO(file_bytes.read()))
    for para in doc.paragraphs:
        para.text = restore_sensitive_data(para.text, replacements)
        set_font(para)
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                cell.text = restore_sensitive_data(cell.text, replacements)
                for p in cell.paragraphs:
                    set_font(p)
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF ===
def sanitize_pdf(file_bytes):
    pdf_in = fitz.open(stream=file_bytes.read(), filetype='pdf')
    pdf_out = fitz.open()
    full_replacements = {}
    for page in pdf_in:
        text = page.get_text()
        new_text, replacements = remove_sensitive_data(text)
        full_replacements.update(replacements)
        new_page = pdf_out.new_page(width=page.rect.width, height=page.rect.height)
        new_page.insert_text((50, 50), new_text, fontsize=11, fontname="helv")
    buffer = BytesIO()
    pdf_out.save(buffer)
    buffer.seek(0)
    return buffer, full_replacements

# === –ö–∞—Ä—Ç–∞ –∑–∞–º–µ–Ω ===
def export_replacements(replacements):
    rep_text = "\n".join(f"{k} ‚Üí {v}" for k, v in replacements.items())
    buffer = BytesIO()
    buffer.write(rep_text.encode("utf-8"))
    buffer.seek(0)
    return buffer

def import_replacements(text_file):
    content = text_file.read().decode("utf-8")
    replacements = {}
    for line in content.strip().splitlines():
        if "‚Üí" in line:
            key, val = line.split("‚Üí", 1)
            replacements[key.strip()] = val.strip()
    return replacements

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit ===
st.set_page_config(page_title="AsiwiAnonymizer", page_icon="üìÑ")
st.title("AsiwiAnonymizer ‚Äî –û–±–µ–∑–ª–∏—á–∏–≤–∞–Ω–∏–µ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ .docx –∏ .pdf")

tab1, tab2 = st.tabs(["üîí –û–±–µ–∑–ª–∏—á–∏—Ç—å", "‚ôªÔ∏è –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å"])

with tab1:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª .docx –∏–ª–∏ .pdf", type=["docx", "pdf"])
    if uploaded_file and st.button("–û–±–µ–∑–ª–∏—á–∏—Ç—å"):
        filetype = uploaded_file.name.split(".")[-1].lower()
        if filetype == "docx":
            output, replacements = sanitize_docx(uploaded_file)
            filename = "–æ–±–µ–∑–ª–∏—á–µ–Ω–Ω—ã–π.docx"
        elif filetype == "pdf":
            output, replacements = sanitize_pdf(uploaded_file)
            filename = "–æ–±–µ–∑–ª–∏—á–µ–Ω–Ω—ã–π.pdf"
        else:
            st.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç.")
            st.stop()

        st.download_button("üìÅ –°–∫–∞—á–∞—Ç—å –æ–±–µ–∑–ª–∏—á–µ–Ω–Ω—ã–π —Ñ–∞–π–ª", data=output, file_name=filename)
        if replacements:
            rep_file = export_replacements(replacements)
            st.download_button("üóÇÔ∏è –°–∫–∞—á–∞—Ç—å –∫–∞—Ä—Ç—É –∑–∞–º–µ–Ω (.txt)", data=rep_file, file_name="–∫–∞—Ä—Ç–∞_–∑–∞–º–µ–Ω.txt")

with tab2:
    file_docx = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–π –æ–±–µ–∑–ª–∏—á–µ–Ω–Ω—ã–π .docx", type=["docx"], key="restore_docx")
    file_map = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∫–∞—Ä—Ç—É –∑–∞–º–µ–Ω (.txt)", type=["txt"], key="restore_map")
    if file_docx and file_map and st.button("–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å"):
        replacements = import_replacements(file_map)
        restored_doc = restore_docx(file_docx, replacements)
        st.download_button("üìÑ –°–∫–∞—á–∞—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π .docx", data=restored_doc, file_name="–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π.docx")
